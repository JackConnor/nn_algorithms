{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jack/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_filter(d, mi, mo, stride):\n",
    "    return (np.random.randn(d, d, mi, mo) * np.sqrt(2.0 / (d * d * mi))).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, d, mi, mo, stride=2, padding='VALID'):\n",
    "        self.W = tf.Variable(init_filter(d, mi, mo, stride))\n",
    "        self.b = tf.Variable(np.zeros(mo, dtype=np.float32))\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = tf.nn.conv2d(\n",
    "            X,\n",
    "            self.W,\n",
    "            strides=[1, self.stride, self.stride, 1],\n",
    "            padding=self.padding\n",
    "        )\n",
    "        X = X + self.b\n",
    "        return X\n",
    "    \n",
    "    def copyFromKerasLayers(self, layer):\n",
    "        W, b = layer.get_weights()\n",
    "        op1 = self.W.assign(W)\n",
    "        op2 = self.b.assign(b)\n",
    "        self.session.run((op1, op2))\n",
    "        \n",
    "    def get_params(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormLayer:\n",
    "    def __init__(self, D):\n",
    "        self.running_mean = tf.Variable(np.zeros(D, dtype=np.float32), trainable=False)\n",
    "        self.running_var = tf.Variable(np.ones(D, dtype=np.float32), trainable=False)\n",
    "        self.gamma = tf.Variable(np.ones(D, dtype=np.float32))\n",
    "        self.beta = tf.Variable(np.ones(D, dtype=np.float32))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return tf.nn.batch_normalization(\n",
    "            X,\n",
    "            self.running_mean,\n",
    "            self.running_var,\n",
    "            self.beta,\n",
    "            self.gamma,\n",
    "            1e-3\n",
    "        )\n",
    "    \n",
    "    def copyFromKerasLayers(self, layer):\n",
    "        gamma, beta, running_mean, running_var = layer.get_weights()\n",
    "        op1 = self.running_mean.assign(running_mean)\n",
    "        op2 = self.running_var.assign(running_var)\n",
    "        op3 = self.gamma.assign(gamma)\n",
    "        op4 = self.beta.assign(beta)\n",
    "        self.session.run((op1, op2, op3, op4))\n",
    "        \n",
    "    def get_params(self):\n",
    "        return [self.running_mean, self.running_var, self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock:\n",
    "    def __init__(self, mi, fm_sizes, stride=2, activation=tf.nn.relu):\n",
    "        assert(len(fm_sizes) == 3)\n",
    "        \n",
    "        self.session = None\n",
    "        self.f = tf.nn.relu\n",
    "        \n",
    "        self.conv1 = ConvLayer(1, mi, fm_sizes[0], stride)\n",
    "        self.bn1 = BatchNormLayer(fm_sizes[0])\n",
    "        self.conv2 = ConvLayer(3, fm_sizes[0], fm_sizes[1], 1, 'SAME')\n",
    "        self.bn2 = BatchNormLayer(fm_sizes[1])\n",
    "        self.conv3 = ConvLayer(1, fm_sizes[1], fm_sizes[2], 1,)\n",
    "        self.bn3 = BatchNormLayer(fm_sizes[2])\n",
    "        \n",
    "        self.convs = ConvLayer(1, mi, fm_sizes[2], stride)\n",
    "        self.bns = BatchNormLayer(fm_sizes[2])\n",
    "        \n",
    "        self.layers = [\n",
    "            self.conv1, self.bn1,\n",
    "            self.conv2, self.bn2,\n",
    "            self.conv3, self.bn3,\n",
    "            self.convs, self.bns,\n",
    "        ]\n",
    "        \n",
    "        self.input_ = tf.placeholder(tf.float32, shape=(1, 224, 224, mi))\n",
    "        self.output = self.forward(self.input_)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        FX = self.conv1.forward(X)\n",
    "        FX = self.bn1.forward(FX)\n",
    "        FX = self.f(FX)\n",
    "        FX = self.conv2.forward(FX)\n",
    "        FX = self.bn2.forward(FX)\n",
    "        FX = self.f(FX)\n",
    "        FX = self.conv3.forward(FX)\n",
    "        FX = self.bn3.forward(FX)\n",
    "        \n",
    "        SX = self.convs.forward(X)\n",
    "        SX = self.bns.forward(SX)\n",
    "        \n",
    "        return self.f(FX + SX)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert(self.session is not None)\n",
    "        return self.session.run(\n",
    "            self.output,\n",
    "            feed_dict={self.input_: X}\n",
    "        )\n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "        self.conv1.session = session\n",
    "        self.bn1.session = session\n",
    "        self.conv2.session = session\n",
    "        self.bn2.session = session\n",
    "        self.conv3.session = session\n",
    "        self.bn3.session = session\n",
    "        self.convs.session = session\n",
    "        self.bns.session = session\n",
    "        \n",
    "    def copyFromKerasLayers(self, layers):\n",
    "        \n",
    "        self.conv1.copyFromKerasLayers(layers[0])\n",
    "        self.bn1.copyFromKerasLayers(layers[0])\n",
    "        self.conv2.copyFromKerasLayers(layers[0])\n",
    "        self.bn2.copyFromKerasLayers(layers[0])\n",
    "        self.conv3.copyFromKerasLayers(layers[0])\n",
    "        self.bn3.copyFromKerasLayers(layers[0])\n",
    "        self.convs.copyFromKerasLayers(layers[0])\n",
    "        self.bns.copyFromKerasLayers(layers[0])\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.get_params()\n",
    "        return params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.shape: (1, 224, 224, 256)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    conv_block = ConvBlock(mi=3, fm_sizes=[64, 64, 256], stride=1)\n",
    "    \n",
    "    X = np.random.random((1, 224, 224, 3))\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as session:\n",
    "        conv_block.set_session(session)\n",
    "        session.run(init)\n",
    "        \n",
    "        output = conv_block.predict(X)\n",
    "        print('output.shape: '  + str(output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
